{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple data parsing + plotting notebook\n",
    "---\n",
    "\n",
    "This notebook will aggregate summary data from a set of corvid runs and parse to hdf5 format and/or plot statitstics.\n",
    "\n",
    "## Generating data\n",
    "To generate a set of runs to analyze, run the `batchrun_haswell.slr` slurm script (currently configured for the haswell node debug queue, as long as it fits into <30 mins). This will take a haswell node and run corvid w/ 64 different random seeds in parallel. To do more concurrent runs, use the `--array=0-M` option when submitting via `sbatch` to submit a job array of M+1 jobs, each running 64 unique random seeds.\n",
    "\n",
    "In the batch script, adjust the `dirName` field to point to your desired storage directory in `$SCRATCH` -- currently I have it to be `$SCRATCH/corvid_demo/$dirName`. Then, provide the `configFile` to adjust which config file you'd like to use.\n",
    "\n",
    "## Formats/Info\n",
    "Array shapes are (number of runs, simulation length in days, d), where d can be 1 for scalar data, 5 for age-binned data. The parser uses a sample summary from the first run in job (`${dataDir}-0/out_0/${summfname}`) to get variable names and the corresponding shapes.\n",
    "\n",
    "If job outputs are in `$SCRATCH`, parsing takes around 2-3s per run for 180 day runs. This changes with file system variability and the size of the summary files. So to parse O(1000) runs, start the parsing cell and then go make some coffee ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from plotting import *\n",
    "from utils import RunParser\n",
    "import os\n",
    "\n",
    "# Directory where hdf5 summaries are saved\n",
    "saveDir= '/global/cfs/projectdirs/covid19/sys_uncertainty/seattle-26/' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Can parse a set of runs generated by the batch submission script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDir = '/global/cscratch1/sd/pharring/corvid_demo/schoolWFH-long' # Where output of slurm job array lives\n",
    "N_jobs_array = 13 # Number of jobs in job array\n",
    "N_per_job = 80 # number of runs per job (equals srun --ntasks in batch script)\n",
    "dat = RunParser(dataDir, Narr=N_jobs_array, Nperjob=N_per_job)\n",
    "dat.parse_runs()\n",
    "h5name = os.path.join(saveDir, dataDir.split('/')[-1]+'.h5')\n",
    "dat.save_h5(h5name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Or load from an hdf5 file if you have already done the above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hdf5 filename to load from\n",
    "h5name = os.path.join(saveDir,'schoolWFH-long.h5')\n",
    "dat = RunParser(load_from_h5=h5name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot daily new symptomatic individuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_daily_new_symptomatic(dat.agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_peakdist(dat.agg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot timeseries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_timeseries(dat.agg, figsz=14, agebins=dat.age_bins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot end-of-sim stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_end(dat.agg, figsz=14, agebins=dat.age_bins)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyROOT - Python3",
   "language": "python",
   "name": "pyroot3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
